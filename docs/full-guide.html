<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Guide - build-kg</title>
<style>
  :root {
    --bg: #0d1117;
    --surface: #161b22;
    --border: #30363d;
    --text: #c9d1d9;
    --text-muted: #8b949e;
    --heading: #f0f6fc;
    --link: #58a6ff;
    --accent: #1f6feb;
    --green: #3fb950;
    --orange: #d29922;
    --red: #f85149;
    --purple: #bc8cff;
    --code-bg: #0d1117;
    --inline-code-bg: #1c2128;
    --nav-height: 56px;
    --sidebar-width: 240px;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  html {
    scroll-behavior: smooth;
    scroll-padding-top: calc(var(--nav-height) + 24px);
  }

  body {
    font-family: 'JetBrains Mono', 'Fira Code', 'SF Mono', 'Cascadia Code', 'Consolas', 'Liberation Mono', monospace;
    background: var(--bg);
    color: var(--text);
    line-height: 1.6;
    font-size: 16px;
  }

  /* ── Fixed Navigation Bar ── */
  .navbar {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    height: var(--nav-height);
    background: var(--surface);
    border-bottom: 1px solid var(--border);
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 0 1.5rem;
    z-index: 1000;
  }

  .navbar-logo {
    font-size: 1.15rem;
    font-weight: 700;
    color: var(--heading);
    text-decoration: none;
    letter-spacing: -0.02em;
  }

  .navbar-logo span {
    color: var(--link);
  }

  .navbar-links {
    display: flex;
    align-items: center;
    gap: 1.5rem;
  }

  .navbar-links a {
    color: var(--text-muted);
    text-decoration: none;
    font-size: 0.9rem;
    font-weight: 500;
    transition: color 0.15s;
  }

  .navbar-links a:hover,
  .navbar-links a.active {
    color: var(--heading);
  }

  .navbar-links a.active {
    color: var(--link);
  }

  /* ── Mobile sidebar toggle ── */
  .sidebar-toggle {
    display: none;
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 6px;
    color: var(--text);
    font-size: 1.25rem;
    width: 36px;
    height: 36px;
    cursor: pointer;
    align-items: center;
    justify-content: center;
    position: fixed;
    top: calc(var(--nav-height) + 12px);
    left: 12px;
    z-index: 999;
  }

  /* ── Fixed Sidebar ── */
  .sidebar {
    position: fixed;
    top: var(--nav-height);
    left: 0;
    bottom: 0;
    width: var(--sidebar-width);
    background: var(--surface);
    border-right: 1px solid var(--border);
    overflow-y: auto;
    padding: 1.25rem 0;
    z-index: 900;
    scrollbar-width: thin;
    scrollbar-color: var(--border) transparent;
  }

  .sidebar::-webkit-scrollbar {
    width: 5px;
  }

  .sidebar::-webkit-scrollbar-track {
    background: transparent;
  }

  .sidebar::-webkit-scrollbar-thumb {
    background: var(--border);
    border-radius: 3px;
  }

  .sidebar-group {
    margin-bottom: 1.25rem;
  }

  .sidebar-group-label {
    font-size: 0.7rem;
    font-weight: 600;
    color: var(--text-muted);
    text-transform: uppercase;
    letter-spacing: 0.08em;
    padding: 0 1.25rem;
    margin-bottom: 0.35rem;
  }

  .sidebar-group ul {
    list-style: none;
  }

  .sidebar-group li a {
    display: block;
    padding: 0.3rem 1.25rem;
    font-size: 0.85rem;
    color: var(--text-muted);
    text-decoration: none;
    border-left: 2px solid transparent;
    transition: color 0.15s, border-color 0.15s, background 0.15s;
  }

  .sidebar-group li a:hover {
    color: var(--text);
    background: rgba(88, 166, 255, 0.04);
  }

  .sidebar-group li a.active {
    color: var(--link);
    border-left-color: var(--link);
    background: rgba(88, 166, 255, 0.06);
  }

  /* ── Main Content ── */
  .main {
    margin-left: var(--sidebar-width);
    margin-top: var(--nav-height);
    padding: 2rem 2.5rem 4rem;
    max-width: 900px;
  }

  /* ── Typography ── */
  h1 {
    font-size: 2.2rem;
    color: var(--heading);
    margin-bottom: 0.5rem;
    letter-spacing: -0.02em;
  }

  h2 {
    font-size: 1.6rem;
    color: var(--heading);
    margin: 2.5rem 0 1rem;
    padding-bottom: 0.4rem;
    border-bottom: 1px solid var(--border);
  }

  h3 {
    font-size: 1.2rem;
    color: var(--heading);
    margin: 1.75rem 0 0.75rem;
  }

  h4 {
    font-size: 1.05rem;
    color: var(--heading);
    margin: 1.25rem 0 0.5rem;
  }

  p {
    margin-bottom: 1rem;
  }

  a {
    color: var(--link);
    text-decoration: none;
  }

  a:hover {
    text-decoration: underline;
  }

  ul, ol {
    margin: 0.75rem 0 1rem 1.5rem;
  }

  li {
    margin-bottom: 0.35rem;
  }

  strong {
    color: var(--heading);
  }

  .lead {
    font-size: 1.1rem;
    color: var(--text-muted);
    margin-bottom: 1.5rem;
    line-height: 1.7;
  }

  .version-badge {
    display: inline-block;
    padding: 0.2rem 0.65rem;
    border-radius: 2rem;
    font-size: 0.75rem;
    font-weight: 600;
    border: 1px solid var(--link);
    color: var(--link);
    vertical-align: middle;
    margin-left: 0.5rem;
  }

  /* ── Code ── */
  pre {
    background: var(--code-bg);
    border: 1px solid var(--border);
    border-radius: 6px;
    padding: 1rem 1.25rem;
    overflow-x: auto;
    margin: 1rem 0;
    font-size: 0.85rem;
    line-height: 1.55;
  }

  code {
    font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
    font-size: 0.875em;
  }

  :not(pre) > code {
    background: var(--inline-code-bg);
    padding: 0.15em 0.4em;
    border-radius: 3px;
    font-size: 0.85em;
  }

  /* ── Tables ── */
  table {
    width: 100%;
    border-collapse: collapse;
    margin: 1rem 0;
    font-size: 0.88rem;
  }

  th, td {
    text-align: left;
    padding: 0.55rem 0.75rem;
    border: 1px solid var(--border);
  }

  th {
    background: var(--surface);
    color: var(--heading);
    font-weight: 600;
    font-size: 0.82rem;
  }

  tr:nth-child(even) {
    background: rgba(22, 27, 34, 0.5);
  }

  /* ── Callouts ── */
  .callout {
    border-left: 3px solid var(--accent);
    background: var(--surface);
    padding: 0.9rem 1.15rem;
    border-radius: 0 6px 6px 0;
    margin: 1rem 0;
    font-size: 0.92rem;
  }

  .callout.tip { border-left-color: var(--green); }
  .callout.warn { border-left-color: var(--orange); }
  .callout.danger { border-left-color: var(--red); }

  .callout-title {
    display: block;
    font-weight: 600;
    margin-bottom: 0.25rem;
    color: var(--heading);
    font-size: 0.85rem;
  }

  .callout.tip .callout-title { color: var(--green); }
  .callout.warn .callout-title { color: var(--orange); }
  .callout.danger .callout-title { color: var(--red); }

  /* ── Pipeline Diagram ── */
  .pipeline {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(95px, 1fr));
    gap: 0.5rem;
    margin: 1.25rem 0;
  }

  .pipeline-step {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 6px;
    padding: 0.65rem 0.5rem;
    text-align: center;
    font-size: 0.78rem;
    position: relative;
  }

  .pipeline-step .phase {
    font-size: 0.65rem;
    color: var(--text-muted);
    text-transform: uppercase;
    letter-spacing: 0.05em;
  }

  .pipeline-step .name {
    font-weight: 600;
    color: var(--heading);
    margin: 0.2rem 0;
    font-size: 0.82rem;
  }

  .pipeline-step .tool {
    font-size: 0.68rem;
    color: var(--purple);
  }

  .pipeline-arrow {
    display: flex;
    align-items: center;
    justify-content: center;
    color: var(--text-muted);
    font-size: 1.1rem;
    min-width: 20px;
  }

  /* ── Command Cards ── */
  .cmd-card {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 6px;
    padding: 1.15rem 1.25rem;
    margin: 0.75rem 0;
  }

  .cmd-card h4 {
    margin-top: 0;
    margin-bottom: 0.5rem;
  }

  .cmd-name {
    font-family: 'SFMono-Regular', Consolas, monospace;
    color: var(--green);
    font-size: 1rem;
    font-weight: 600;
  }

  /* ── FAQ ── */
  .faq-item {
    margin-bottom: 1.25rem;
  }

  .faq-q {
    font-weight: 600;
    color: var(--heading);
    margin-bottom: 0.35rem;
    font-size: 0.95rem;
  }

  .faq-a {
    color: var(--text);
    font-size: 0.92rem;
  }

  /* ── Section anchor (for scroll offset) ── */
  section {
    padding-top: 0.5rem;
    margin-bottom: 1.5rem;
  }

  /* ── Comparison highlights ── */
  .compare-highlight {
    color: var(--green);
    font-weight: 600;
  }

  /* ── Footer ── */
  .footer {
    text-align: center;
    padding: 2.5rem 0 2rem;
    color: var(--text-muted);
    font-size: 0.82rem;
    border-top: 1px solid var(--border);
    margin-top: 2rem;
  }

  /* ── Responsive ── */
  @media (max-width: 768px) {
    .sidebar {
      transform: translateX(-100%);
      transition: transform 0.25s ease;
    }

    .sidebar.open {
      transform: translateX(0);
    }

    .sidebar-toggle {
      display: flex;
    }

    .main {
      margin-left: 0;
      padding: 1.5rem 1.25rem 3rem;
    }

    h1 { font-size: 1.75rem; }
    h2 { font-size: 1.35rem; }

    .pipeline {
      grid-template-columns: repeat(4, 1fr);
    }

    table {
      font-size: 0.8rem;
    }

    th, td {
      padding: 0.4rem 0.5rem;
    }

    .sidebar-overlay {
      display: none;
      position: fixed;
      top: var(--nav-height);
      left: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.5);
      z-index: 899;
    }

    .sidebar-overlay.visible {
      display: block;
    }
  }

  @media (max-width: 480px) {
    .pipeline {
      grid-template-columns: repeat(2, 1fr);
    }
  }
</style>
</head>
<body>

<!-- ═══════════ Navigation Bar ═══════════ -->
<nav class="navbar">
  <a href="index.html" class="navbar-logo">build-<span>kg</span></a>
  <div class="navbar-links">
    <a href="index.html">Home</a>
    <a href="guide.html" class="active">Guide</a>
    <a href="https://github.com/agtm1199/build-kg" target="_blank" rel="noopener">GitHub</a>
  </div>
</nav>

<!-- ═══════════ Mobile Sidebar Toggle ═══════════ -->
<button class="sidebar-toggle" id="sidebarToggle" aria-label="Toggle navigation">&#9776;</button>
<div class="sidebar-overlay" id="sidebarOverlay"></div>

<!-- ═══════════ Sidebar ═══════════ -->
<aside class="sidebar" id="sidebar">

  <div class="sidebar-group">
    <div class="sidebar-group-label">Getting Started</div>
    <ul>
      <li><a href="#introduction">Introduction</a></li>
      <li><a href="#installation">Installation</a></li>
      <li><a href="#quick-start">Quick Start</a></li>
    </ul>
  </div>

  <div class="sidebar-group">
    <div class="sidebar-group-label">Pipeline</div>
    <ul>
      <li><a href="#pipeline-overview">Overview</a></li>
      <li><a href="#ontology-system">Ontology System</a></li>
      <li><a href="#domain-profiles">Domain Profiles</a></li>
    </ul>
  </div>

  <div class="sidebar-group">
    <div class="sidebar-group-label">CLI Reference</div>
    <ul>
      <li><a href="#cli-crawl">build-kg-crawl</a></li>
      <li><a href="#cli-chunk">build-kg-chunk</a></li>
      <li><a href="#cli-load">build-kg-load</a></li>
      <li><a href="#cli-parse">build-kg-parse</a></li>
    </ul>
  </div>

  <div class="sidebar-group">
    <div class="sidebar-group-label">Advanced</div>
    <ul>
      <li><a href="#configuration">Configuration</a></li>
      <li><a href="#batch-api">Batch API</a></li>
      <li><a href="#manifest-format">Manifest Format</a></li>
    </ul>
  </div>

  <div class="sidebar-group">
    <div class="sidebar-group-label">Reference</div>
    <ul>
      <li><a href="#examples">Examples</a></li>
      <li><a href="#cost">Cost</a></li>
    </ul>
  </div>

  <div class="sidebar-group">
    <div class="sidebar-group-label">Help</div>
    <ul>
      <li><a href="#troubleshooting">Troubleshooting</a></li>
      <li><a href="#faq">FAQ</a></li>
    </ul>
  </div>

</aside>

<!-- ═══════════ Main Content ═══════════ -->
<div class="main">

<!-- ────────── Introduction ────────── -->
<section id="introduction">
  <h1>Usage Guide <span class="version-badge">v0.2.0</span></h1>
  <p class="lead">
    build-kg is a Claude Code skill that turns any topic into a structured knowledge graph stored in
    <a href="https://age.apache.org/" target="_blank" rel="noopener">Apache AGE</a> (PostgreSQL).
    No vendor lock-in. No hosting fees. Just your own database.
  </p>
  <p>
    Give build-kg a topic and it autonomously generates an ontology, discovers authoritative sources,
    crawls documentation, chunks and loads documents, parses every fragment with an LLM, and produces
    a queryable graph you can explore with standard Cypher queries.
  </p>

  <h3>How it's different</h3>
  <table>
    <tr><th></th><th>build-kg</th><th>LangChain / LlamaIndex</th><th>Neo4j Aura</th></tr>
    <tr><td><strong>Graph hosting</strong></td><td class="compare-highlight">Your own PostgreSQL</td><td>Their infra</td><td>Neo4j cloud ($$$)</td></tr>
    <tr><td><strong>Vendor lock-in</strong></td><td class="compare-highlight">None &mdash; it's just AGE</td><td>Their SDK</td><td>Their platform</td></tr>
    <tr><td><strong>Ontology</strong></td><td class="compare-highlight">Auto-generated by Claude</td><td>You define it</td><td>You define it</td></tr>
    <tr><td><strong>Interface</strong></td><td><code>/build-kg</code> in Claude Code</td><td>Python code</td><td>Dashboard / API</td></tr>
    <tr><td><strong>Cost</strong></td><td>LLM API calls only</td><td>LLM + hosting</td><td>LLM + hosting + platform</td></tr>
  </table>
</section>

<!-- ────────── Installation ────────── -->
<section id="installation">
  <h2>Installation</h2>

  <h3>Prerequisites</h3>
  <ul>
    <li><strong>Python 3.10+</strong></li>
    <li><strong>Docker</strong> &mdash; for PostgreSQL + Apache AGE</li>
    <li><strong>OpenAI API key</strong> &mdash; for LLM-based text parsing</li>
  </ul>

  <h3>From source (recommended)</h3>
<pre><code>git clone https://github.com/agtm1199/build-kg.git
cd build-kg

# Full setup: creates venv, starts DB, initializes graph
make setup

# Or step-by-step:
python3 -m venv venv
source venv/bin/activate
pip install -e &quot;.[dev]&quot;
crawl4ai-setup
docker compose -f db/docker-compose.yml up -d
python -m build_kg.setup_graph</code></pre>

  <h3>From PyPI</h3>
<pre><code>pip install build-kg</code></pre>

  <h3>Configure your environment</h3>
<pre><code>cp .env.example .env
# Edit .env and set OPENAI_API_KEY=sk-...

# Verify everything works
make verify</code></pre>

  <div class="callout tip">
    <span class="callout-title">Tip</span>
    The default <code>.env.example</code> has database credentials that match the Docker container.
    You only need to add your <code>OPENAI_API_KEY</code>.
  </div>
</section>

<!-- ────────── Quick Start ────────── -->
<section id="quick-start">
  <h2>Quick Start</h2>

  <h3>With Claude Code (recommended)</h3>
  <p>
    If you use <a href="https://docs.anthropic.com/en/docs/claude-code" target="_blank" rel="noopener">Claude Code</a>,
    the <code>/build-kg</code> skill automates the entire pipeline:
  </p>
<pre><code>/build-kg kubernetes networking
/build-kg machine learning optimization algorithms
/build-kg GDPR compliance requirements for SaaS companies
/build-kg full regulatory compliance landscape of Singapore for F&amp;B</code></pre>
  <p>This runs all phases autonomously &mdash; ontology generation, source discovery, crawling, chunking, loading, parsing, and validation.</p>

  <h3>With CLI tools (manual 6-step process)</h3>
<pre><code># 1. Crawl a website
build-kg-crawl --url &quot;https://kubernetes.io/docs/concepts/services-networking/&quot; \
  --depth 2 --pages 50 --output ./output/

# 2. Chunk the crawled content
build-kg-chunk ./output/ ./chunks/ --strategy by_title --max-chars 1000

# 3. Load chunks into the database
build-kg-load ./chunks/ --manifest ./crawl_manifest.json

# 4. Set up the graph with your ontology
AGE_GRAPH_NAME=kg_k8s_net python -m build_kg.setup_graph --ontology ./ontology.yaml

# 5. Parse fragments into the knowledge graph (sync)
AGE_GRAPH_NAME=kg_k8s_net build-kg-parse --ontology ./ontology.yaml

# 6. Or use the Batch API (50% cheaper)
build-kg-parse-batch prepare --ontology ./ontology.yaml
build-kg-parse-batch submit batch_data/batch_requests.jsonl
build-kg-parse-batch status &lt;batch_id&gt; --watch
build-kg-parse-batch process &lt;batch_id&gt; --ontology ./ontology.yaml</code></pre>
</section>

<!-- ────────── Pipeline Overview ────────── -->
<section id="pipeline-overview">
  <h2>Pipeline Overview</h2>
  <p>
    build-kg transforms any topic into a knowledge graph through an 8-phase pipeline.
    Each phase produces an artifact that feeds the next.
  </p>

  <div class="pipeline">
    <div class="pipeline-step">
      <div class="phase">Phase 0</div>
      <div class="name">Init</div>
      <div class="tool">graph name, dirs</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 0.5</div>
      <div class="name">Ontology</div>
      <div class="tool">auto-gen or profile</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 1</div>
      <div class="name">Discover</div>
      <div class="tool">WebSearch</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 2</div>
      <div class="name">Crawl</div>
      <div class="tool">Crawl4AI</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 3</div>
      <div class="name">Chunk</div>
      <div class="tool">Unstructured</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 4</div>
      <div class="name">Load</div>
      <div class="tool">PostgreSQL</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 5</div>
      <div class="name">Parse</div>
      <div class="tool">GPT-4o-mini</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 6</div>
      <div class="name">Validate</div>
      <div class="tool">Cypher queries</div>
    </div>
  </div>

  <h3>Phase 0: Initialize</h3>
  <p>
    Create a working directory and choose a graph name. Naming conventions:
  </p>
  <ul>
    <li><strong>Regulatory topics</strong>: <code>reg_&lt;country_code&gt;_&lt;domain&gt;</code> (e.g., <code>reg_sg_fb</code> for Singapore F&amp;B)</li>
    <li><strong>Generic topics</strong>: <code>kg_&lt;topic&gt;</code> (e.g., <code>kg_k8s_net</code> for Kubernetes networking)</li>
  </ul>

  <h3>Phase 0.5: Ontology Generation</h3>
  <p>
    The key differentiator of build-kg. For generic topics, Claude analyzes your subject and
    auto-generates an ontology &mdash; node types, edge types, properties, and a JSON schema.
    For regulatory domain profiles, a pre-built ontology is loaded from the profile YAML.
    The generated ontology typically includes 3&ndash;7 node types and is saved to
    <code>ontology.yaml</code> in the working directory.
  </p>

  <h3>Phase 1: Source Discovery</h3>
  <p>
    A 5-round methodology identifies authoritative sources for the topic.
    Each round progressively deepens coverage:
  </p>
  <table>
    <tr><th>Round</th><th>Name</th><th>Method</th><th>Purpose</th></tr>
    <tr><td>1</td><td>Landscape Mapping</td><td>8&ndash;15 parallel web searches</td><td>Identify authoritative sources</td></tr>
    <tr><td>2</td><td>Deep Source Discovery</td><td>Fetch main pages</td><td>Find documents, standards, specs</td></tr>
    <tr><td>3</td><td>Coverage Verification</td><td>Cross-reference checklist</td><td>Identify gaps in topic coverage</td></tr>
    <tr><td>4</td><td>Gap Filling</td><td>Targeted searches</td><td>Fill gaps; aim for 90%+ coverage</td></tr>
    <tr><td>5</td><td>Secondary Sources</td><td>Supporting material</td><td>Add context and references</td></tr>
  </table>
  <p>
    The output is a <strong>crawl manifest</strong> (<code>crawl_manifest.json</code>) listing every URL with
    metadata and priority tiers.
  </p>

  <h3>Phase 2: Crawl</h3>
  <p>
    Breadth-first web crawling using <a href="https://github.com/unclecode/crawl4ai" target="_blank" rel="noopener">Crawl4AI</a>
    with headless Chromium. Supports JavaScript-rendered pages. Pages are saved as markdown.
    Priority tiers control depth, page limits, and delay:
  </p>
  <table>
    <tr><th>Tier</th><th>Description</th><th>Depth</th><th>Max Pages</th><th>Delay</th></tr>
    <tr><td>P1</td><td>Primary authoritative</td><td>3</td><td>100</td><td>1500 ms</td></tr>
    <tr><td>P2</td><td>Secondary documentation</td><td>2</td><td>50</td><td>1500 ms</td></tr>
    <tr><td>P3</td><td>Supporting guides</td><td>1</td><td>25</td><td>2000 ms</td></tr>
    <tr><td>P4</td><td>Reference material</td><td>1</td><td>15</td><td>2000 ms</td></tr>
  </table>

  <h3>Phase 3: Chunk</h3>
  <p>
    Documents are split into semantically coherent fragments using the
    <a href="https://github.com/Unstructured-IO/unstructured" target="_blank" rel="noopener">Unstructured</a> library.
    Two strategies are available:
  </p>
  <ul>
    <li><strong><code>by_title</code></strong> (recommended) &mdash; respects headings and section boundaries</li>
    <li><strong><code>basic</code></strong> &mdash; fills chunks uniformly to the character limit</li>
  </ul>
  <p>Each chunk is saved as JSON with metadata: source path, index, SHA-256 fingerprint, and position.</p>

  <h3>Phase 4: Load</h3>
  <p>
    Chunks are loaded into PostgreSQL tables (<code>source_document</code> and <code>source_fragment</code>)
    with metadata from the crawl manifest. Adjacent chunks are linked via <code>context_before</code>
    and <code>context_after</code> fields.
  </p>

  <h3>Phase 5: Parse</h3>
  <p>
    Each fragment is sent to GPT-4o-mini with a structured prompt derived from the ontology.
    The LLM returns entities and relationships in JSON, which are loaded into Apache AGE as graph
    vertices and edges. Two parser variants exist:
  </p>
  <ul>
    <li><strong>Synchronous</strong> (<code>build-kg-parse</code>) &mdash; real-time, standard pricing</li>
    <li><strong>Batch</strong> (<code>build-kg-parse-batch</code>) &mdash; 50% cheaper, results in 1&ndash;24 hours</li>
  </ul>

  <h3>Phase 6: Validate</h3>
  <p>
    Cypher queries count nodes by label from the ontology and produce a report card of the
    completed graph.
  </p>
</section>

<!-- ────────── Ontology System ────────── -->
<section id="ontology-system">
  <h2>Ontology System</h2>
  <p>
    The ontology defines <em>what</em> your knowledge graph looks like &mdash; the types of
    nodes, their properties, and how they connect via edges.
  </p>

  <h3>Auto-Generated Ontology</h3>
  <p>
    For generic topics (using the <code>default</code> profile or no profile), Claude auto-generates
    an ontology tailored to the subject. Example for <strong>"kubernetes networking"</strong>:
  </p>
<pre><code>nodes:
  - label: Component
    description: &quot;A Kubernetes networking component&quot;
    properties:
      name: string
      type: string
      description: string
      layer: string
  - label: Concept
    description: &quot;A networking concept or protocol&quot;
    properties:
      name: string
      description: string
      category: string
  - label: Configuration
    description: &quot;A configuration option or setting&quot;
    properties:
      name: string
      description: string
      default_value: string
edges:
  - label: USES
    source: Component
    target: Concept
    description: &quot;Component uses this concept&quot;
  - label: CONFIGURES
    source: Configuration
    target: Component
    description: &quot;Configuration applies to component&quot;
  - label: DEPENDS_ON
    source: Component
    target: Component
    description: &quot;Component depends on another&quot;
root_node: Component
json_schema: |
  {
    &quot;entities&quot;: [
      {&quot;_label&quot;: &quot;Component|Concept|Configuration&quot;, &quot;name&quot;: &quot;...&quot;, ...}
    ],
    &quot;relationships&quot;: [
      {&quot;_label&quot;: &quot;USES|CONFIGURES|DEPENDS_ON&quot;, &quot;_from_index&quot;: 0, &quot;_to_index&quot;: 1}
    ]
  }</code></pre>

  <h3>Pre-Built Ontology (Domain Profiles)</h3>
  <p>
    Regulatory domain profiles include a pre-built ontology with a
    <code>Provision &rarr; Requirement &rarr; Constraint</code> structure. This ontology is
    optimized for compliance analysis with machine-testable constraints.
  </p>
  <p>
    The LLM extracts entities using this fixed schema so that every provision maps to
    requirements with deontic modalities (<code>must</code>, <code>may</code>, <code>should</code>)
    and constraints with logic types (<code>threshold</code>, <code>pattern</code>,
    <code>enumeration</code>, <code>boolean</code>).
  </p>

  <h3>OntologyConfig Data Model</h3>
  <table>
    <tr><th>Model</th><th>Fields</th><th>Description</th></tr>
    <tr>
      <td><code>NodeDef</code></td>
      <td><code>label</code>, <code>description</code>, <code>properties</code></td>
      <td>A node type in the graph. Properties map name to type (<code>string</code>, <code>number</code>, <code>boolean</code>, <code>list</code>).</td>
    </tr>
    <tr>
      <td><code>EdgeDef</code></td>
      <td><code>label</code>, <code>source</code>, <code>target</code>, <code>description</code></td>
      <td>An edge type connecting two node types.</td>
    </tr>
    <tr>
      <td><code>OntologyConfig</code></td>
      <td><code>nodes</code>, <code>edges</code>, <code>root_node</code>, <code>json_schema</code></td>
      <td>Complete ontology definition. <code>root_node</code> is the primary type that maps 1:1 to source fragments.</td>
    </tr>
  </table>

  <div class="callout tip">
    <span class="callout-title">Tip</span>
    The ontology is the most important part of your knowledge graph. When auto-generated, review
    it carefully before proceeding. You can edit the <code>ontology.yaml</code> file to adjust
    node types, properties, and edge definitions.
  </div>
</section>

<!-- ────────── Domain Profiles ────────── -->
<section id="domain-profiles">
  <h2>Domain Profiles</h2>
  <p>
    Domain profiles are YAML files that parameterize the entire pipeline: ontology, LLM prompt,
    ID extraction patterns, and source discovery templates.
  </p>

  <h3>Built-in Profiles</h3>
  <table>
    <tr><th>Profile</th><th>Ontology</th><th>Domain</th></tr>
    <tr><td><code>default</code></td><td>None (auto-generated)</td><td>Any topic</td></tr>
    <tr><td><code>food-safety</code></td><td>Provision / Requirement / Constraint</td><td>CFIA, FDA, SFA food safety</td></tr>
    <tr><td><code>financial-aml</code></td><td>Provision / Requirement / Constraint</td><td>AML/KYC financial compliance</td></tr>
    <tr><td><code>data-privacy</code></td><td>Provision / Requirement / Constraint</td><td>GDPR, CCPA, data protection</td></tr>
  </table>

  <h3>Selecting a Profile</h3>
<pre><code># Via CLI flag
build-kg-parse --domain financial-aml

# Via environment variable
DOMAIN=financial-aml build-kg-parse

# Custom profile file
build-kg-parse --domain /path/to/my-domain.yaml

# List all available profiles
build-kg-domains</code></pre>

  <h3>Profile Inheritance</h3>
  <p>
    Profiles can inherit from a base using <code>extends: default</code>. Child fields override
    parent fields via deep merge. This avoids repeating universal configuration in every profile.
  </p>
  <p>Resolution order for the active profile:</p>
  <ol>
    <li><code>--domain</code> CLI flag (highest priority)</li>
    <li><code>DOMAIN</code> environment variable</li>
    <li>Default: <code>food-safety</code></li>
  </ol>

  <h3>Profile Structure</h3>
<pre><code>name: &quot;My Domain&quot;
description: &quot;Custom domain profile&quot;
version: &quot;1.0&quot;
extends: default

ontology:
  root_node: MyEntity
  nodes:
    - label: MyEntity
      description: &quot;Primary entity type&quot;
      properties: {name: string, type: string}
  edges:
    - label: RELATES_TO
      source: MyEntity
      target: MyEntity
  json_schema: |
    {&quot;entities&quot;: [...], &quot;relationships&quot;: [...]}

parsing:
  system_message: &quot;You are an expert in...&quot;
  requirement_types: [...]

id_patterns:
  patterns: {}

discovery:
  search_templates:
    - &quot;&lt;topic&gt; official documentation&quot;
  sub_domains:
    - name: &quot;Sub-area 1&quot;
      description: &quot;...&quot;</code></pre>

  <p>
    A profile controls four pipeline aspects: <strong>Ontology</strong> (node/edge types),
    <strong>Parsing</strong> (system message, requirement types), <strong>ID Extraction</strong>
    (regex patterns for regulatory IDs), and <strong>Discovery</strong> (search templates, sub-domains).
  </p>
</section>

<!-- ────────── CLI: build-kg-crawl ────────── -->
<section id="cli-crawl">
  <h2>CLI Reference: build-kg-crawl</h2>
  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-crawl</span></h4>
    <p>Crawl websites to markdown using headless Chromium via Crawl4AI.</p>

    <h4>Usage</h4>
<pre><code>build-kg-crawl --url URL [options]</code></pre>

    <h4>Options</h4>
    <table>
      <tr><th>Flag</th><th>Default</th><th>Description</th></tr>
      <tr><td><code>--url URL</code></td><td>(required)</td><td>Starting URL to crawl</td></tr>
      <tr><td><code>--depth N</code></td><td>2</td><td>Maximum crawl depth</td></tr>
      <tr><td><code>--pages N</code></td><td>10</td><td>Maximum pages to visit</td></tr>
      <tr><td><code>--delay MS</code></td><td>1000</td><td>Delay between visits (ms)</td></tr>
      <tr><td><code>--format FMT</code></td><td>markdown</td><td>Output format: markdown, html, json</td></tr>
      <tr><td><code>--output DIR</code></td><td>./output</td><td>Output directory</td></tr>
    </table>

    <h4>Behavior</h4>
    <ul>
      <li>Performs breadth-first traversal within the same domain</li>
      <li>Supports JavaScript-rendered pages (headless Chromium)</li>
      <li>Each page is saved as a separate markdown file</li>
      <li>Respects configured delay between requests</li>
    </ul>

    <h4>Examples</h4>
<pre><code># Crawl Kubernetes networking docs (up to 50 pages, depth 2)
build-kg-crawl --url &quot;https://kubernetes.io/docs/concepts/services-networking/&quot; \
  --depth 2 --pages 50 --output ./crawl_output/

# Shallow crawl of a single site
build-kg-crawl --url &quot;https://example.com/docs&quot; --depth 1 --pages 20

# Slower crawl with longer delay
build-kg-crawl --url &quot;https://gov.example.org/regulations&quot; \
  --depth 3 --pages 100 --delay 2000</code></pre>
  </div>
</section>

<!-- ────────── CLI: build-kg-chunk ────────── -->
<section id="cli-chunk">
  <h2>CLI Reference: build-kg-chunk</h2>
  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-chunk</span></h4>
    <p>Chunk documents into JSON fragments using the Unstructured library.</p>

    <h4>Usage</h4>
<pre><code>build-kg-chunk &lt;input_dir&gt; &lt;output_dir&gt; [options]</code></pre>

    <h4>Arguments</h4>
    <table>
      <tr><th>Argument</th><th>Description</th></tr>
      <tr><td><code>&lt;input_dir&gt;</code></td><td>Directory with <code>.md</code> / <code>.pdf</code> files</td></tr>
      <tr><td><code>&lt;output_dir&gt;</code></td><td>Output directory for JSON chunks</td></tr>
    </table>

    <h4>Options</h4>
    <table>
      <tr><th>Flag</th><th>Default</th><th>Description</th></tr>
      <tr><td><code>--strategy</code></td><td>by_title</td><td>Chunking strategy: <code>by_title</code> or <code>basic</code></td></tr>
      <tr><td><code>--max-chars N</code></td><td>1000</td><td>Maximum characters per chunk</td></tr>
      <tr><td><code>--overlap N</code></td><td>0</td><td>Character overlap between chunks</td></tr>
    </table>

    <h4>Strategies</h4>
    <ul>
      <li><strong><code>by_title</code></strong> &mdash; respects document structure; starts new chunks at heading boundaries while staying under the character limit. Recommended for most use cases.</li>
      <li><strong><code>basic</code></strong> &mdash; fills chunks to the maximum character limit without regard for document structure. Useful for unstructured text.</li>
    </ul>
    <p>Each chunk JSON includes: source path, chunk index, SHA-256 fingerprint, and position (<code>first</code> / <code>middle</code> / <code>last</code> / <code>only</code>).</p>

    <h4>Examples</h4>
<pre><code># Default chunking (by_title, 1000 chars)
build-kg-chunk ./crawl_output/ ./chunks/

# Basic strategy with larger chunks
build-kg-chunk ./crawl_output/ ./chunks/ --strategy basic --max-chars 2000

# Smaller chunks with overlap for dense text
build-kg-chunk ./crawl_output/ ./chunks/ --max-chars 500 --overlap 100</code></pre>
  </div>
</section>

<!-- ────────── CLI: build-kg-load ────────── -->
<section id="cli-load">
  <h2>CLI Reference: build-kg-load</h2>
  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-load</span></h4>
    <p>Load JSON chunks into PostgreSQL with metadata from the crawl manifest.</p>

    <h4>Usage</h4>
<pre><code>build-kg-load &lt;chunk_dir&gt; --manifest &lt;path&gt; [options]</code></pre>

    <h4>Arguments</h4>
    <table>
      <tr><th>Argument</th><th>Description</th></tr>
      <tr><td><code>&lt;chunk_dir&gt;</code></td><td>Directory with JSON chunk files</td></tr>
    </table>

    <h4>Options</h4>
    <table>
      <tr><th>Flag</th><th>Default</th><th>Description</th></tr>
      <tr><td><code>--manifest PATH</code></td><td>(required)</td><td>Path to <code>crawl_manifest.json</code></td></tr>
      <tr><td><code>--dry-run</code></td><td>off</td><td>Preview what would be inserted without writing to DB</td></tr>
    </table>

    <h4>How it works</h4>
    <ul>
      <li>Reads chunk JSON files and inserts rows into <code>source_document</code> and <code>source_fragment</code> tables</li>
      <li>Matches each chunk file to its source entry in the manifest by looking for the <code>source_name</code> in the file path</li>
      <li>Links adjacent chunks via <code>context_before</code> and <code>context_after</code> fields (last/first 200 characters)</li>
      <li>For generic topics, <code>jurisdiction</code>, <code>authority</code>, and <code>doc_type</code> fields are nullable</li>
      <li>Deduplicates by <code>filepath</code> (upsert on conflict)</li>
    </ul>

    <h4>Examples</h4>
<pre><code># Standard load
build-kg-load ./chunks/ --manifest ./crawl_manifest.json

# Preview without inserting
build-kg-load ./chunks/ --manifest ./crawl_manifest.json --dry-run</code></pre>
  </div>
</section>

<!-- ────────── CLI: build-kg-parse ────────── -->
<section id="cli-parse">
  <h2>CLI Reference: build-kg-parse</h2>

  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-parse</span> <span style="color: var(--text-muted); font-size: 0.85rem;">(synchronous)</span></h4>
    <p>Parse fragments into graph nodes and edges using OpenAI in real-time.</p>

    <h4>Usage</h4>
<pre><code>build-kg-parse [options]</code></pre>

    <h4>Options</h4>
    <table>
      <tr><th>Flag</th><th>Default</th><th>Description</th></tr>
      <tr><td><code>--limit N</code></td><td>all</td><td>Max fragments to process</td></tr>
      <tr><td><code>--offset N</code></td><td>0</td><td>Skip first N fragments</td></tr>
      <tr><td><code>--jurisdiction CODE</code></td><td>all</td><td>Filter by jurisdiction code</td></tr>
      <tr><td><code>--domain NAME</code></td><td>food-safety</td><td>Domain profile name or path</td></tr>
      <tr><td><code>--ontology PATH</code></td><td>none</td><td>Ontology YAML file (enables ontology-driven mode)</td></tr>
      <tr><td><code>--test</code></td><td>off</td><td>Process only 5 fragments (for verification)</td></tr>
    </table>
  </div>

  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-parse-batch</span> <span style="color: var(--text-muted); font-size: 0.85rem;">(batch &mdash; 50% cheaper)</span></h4>
    <p>Parse fragments using the OpenAI Batch API. Four subcommands handle the batch lifecycle.</p>

    <h4>Usage</h4>
<pre><code># 1. Prepare: generate the JSONL request file
build-kg-parse-batch prepare [--ontology PATH] [--jurisdiction CODE]

# 2. Submit: upload the JSONL to OpenAI
build-kg-parse-batch submit &lt;batch_file&gt;

# 3. Status: monitor progress (optionally auto-refresh)
build-kg-parse-batch status &lt;batch_id&gt; [--watch]

# 4. Process: download results and load into the graph
build-kg-parse-batch process &lt;batch_id&gt; [--ontology PATH]</code></pre>
  </div>

  <h3>Parsing Modes</h3>
  <p>The parser operates in one of two modes depending on the ontology:</p>
  <ul>
    <li><strong>Ontology-driven mode</strong> &mdash; when <code>--ontology</code> is provided or the domain profile has an ontology section, the parser creates vertices and edges dynamically from the LLM's JSON output.</li>
    <li><strong>Legacy regulatory mode</strong> &mdash; when no ontology is present, the parser uses the hardcoded Provision / Requirement / Constraint structure.</li>
  </ul>

  <h3>Cost Comparison</h3>
  <table>
    <tr><th>Factor</th><th>Sync (<code>build-kg-parse</code>)</th><th>Batch (<code>build-kg-parse-batch</code>)</th></tr>
    <tr><td>Cost</td><td>~$0.30 per 1,000 fragments</td><td>~$0.15 per 1,000 fragments</td></tr>
    <tr><td>Latency</td><td>Seconds per fragment</td><td>1&ndash;24 hours for entire batch</td></tr>
    <tr><td>Best for</td><td>&lt;500 fragments, debugging</td><td>&gt;=500 fragments, overnight runs</td></tr>
    <tr><td>Rate limiting</td><td><code>RATE_LIMIT_DELAY</code> (default 1s)</td><td>Handled by OpenAI</td></tr>
    <tr><td>Error handling</td><td>Immediate per fragment</td><td>Collected in output file</td></tr>
    <tr><td>Resumability</td><td><code>--offset</code> to skip processed</td><td>Resubmit failed items</td></tr>
  </table>

  <h3>Batch Workflow</h3>
  <ol>
    <li>Run <code>build-kg-parse --test</code> to verify with 5 fragments (cost: &lt; $0.01)</li>
    <li>If results look good, run <code>build-kg-parse-batch prepare</code> to generate the JSONL</li>
    <li>Submit with <code>build-kg-parse-batch submit</code></li>
    <li>Monitor with <code>build-kg-parse-batch status --watch</code></li>
    <li>Process results with <code>build-kg-parse-batch process</code></li>
  </ol>
</section>

<!-- ────────── Configuration ────────── -->
<section id="configuration">
  <h2>Configuration</h2>
  <p>All configuration is via <code>.env</code> file or environment variables.</p>

  <table>
    <tr><th>Variable</th><th>Default</th><th>Description</th></tr>
    <tr><td><code>DB_HOST</code></td><td><code>localhost</code></td><td>PostgreSQL host</td></tr>
    <tr><td><code>DB_PORT</code></td><td><code>5432</code></td><td>PostgreSQL port</td></tr>
    <tr><td><code>DB_NAME</code></td><td><code>buildkg</code></td><td>Database name</td></tr>
    <tr><td><code>DB_USER</code></td><td><code>buildkg</code></td><td>Database user</td></tr>
    <tr><td><code>DB_PASSWORD</code></td><td>&mdash;</td><td>Database password <strong>(required)</strong></td></tr>
    <tr><td><code>OPENAI_API_KEY</code></td><td>&mdash;</td><td>OpenAI API key <strong>(required)</strong></td></tr>
    <tr><td><code>OPENAI_MODEL</code></td><td><code>gpt-4o-mini</code></td><td>Model used for parsing</td></tr>
    <tr><td><code>AGE_GRAPH_NAME</code></td><td><code>reg_ca</code></td><td>Apache AGE graph name</td></tr>
    <tr><td><code>BATCH_SIZE</code></td><td><code>10</code></td><td>Fragments per processing batch</td></tr>
    <tr><td><code>MAX_WORKERS</code></td><td><code>3</code></td><td>Concurrent worker threads</td></tr>
    <tr><td><code>DOMAIN</code></td><td><code>food-safety</code></td><td>Domain profile name or file path</td></tr>
    <tr><td><code>RATE_LIMIT_DELAY</code></td><td><code>1.0</code></td><td>Seconds between API calls (sync parser)</td></tr>
  </table>

  <div class="callout warn">
    <span class="callout-title">Important</span>
    <code>DB_PASSWORD</code> and <code>OPENAI_API_KEY</code> are required. All other variables
    have sensible defaults. Run <code>build-kg-verify</code> to check your configuration.
  </div>
</section>

<!-- ────────── Batch API ────────── -->
<section id="batch-api">
  <h2>Batch API</h2>
  <p>
    The OpenAI Batch API provides a 50% cost reduction for non-time-sensitive workloads.
    build-kg wraps the Batch API with a four-step workflow: <code>prepare</code>,
    <code>submit</code>, <code>status</code>, <code>process</code>.
  </p>

  <h3>Sync vs. Batch</h3>
  <table>
    <tr><th></th><th>Sync Parser</th><th>Batch Parser</th></tr>
    <tr><td>Cost per 1k fragments</td><td>~$0.30</td><td class="compare-highlight">~$0.15</td></tr>
    <tr><td>Turnaround</td><td>Minutes</td><td>1&ndash;24 hours</td></tr>
    <tr><td>Best for</td><td>Small runs, debugging</td><td>Production runs &gt;= 500 fragments</td></tr>
  </table>

  <h3>Cost Estimate Formula</h3>
<pre><code>estimated_cost = (fragments * avg_tokens_per_fragment) / 1,000,000 * price_per_million_tokens

# GPT-4o-mini typical (~500 input + ~300 output tokens per fragment):
#   Sync:  ~$0.00030 per fragment
#   Batch: ~$0.00015 per fragment</code></pre>

  <h3>Recommended Workflow</h3>
  <ol>
    <li>Run <code>build-kg-parse --test</code> to verify with 5 fragments (cost: &lt; $0.01)</li>
    <li>If results look good, use <code>build-kg-parse-batch</code> for the full run</li>
    <li>Submit the batch before end of day; process results the next morning</li>
  </ol>
</section>

<!-- ────────── Manifest Format ────────── -->
<section id="manifest-format">
  <h2>Manifest Format</h2>
  <p>
    The crawl manifest (<code>crawl_manifest.json</code>) is generated during Phase 1 (Source Discovery)
    and drives the crawl and load phases. It contains metadata for every source to crawl.
  </p>

  <h3>Schema Overview</h3>
<pre><code>{
  &quot;topic&quot;: &quot;kubernetes networking&quot;,
  &quot;graph_name&quot;: &quot;kg_k8s_net&quot;,
  &quot;created_at&quot;: &quot;2026-02-20T10:00:00Z&quot;,
  &quot;sources&quot;: [
    {
      &quot;source_name&quot;: &quot;kubernetes-io-networking&quot;,
      &quot;url&quot;: &quot;https://kubernetes.io/docs/concepts/services-networking/&quot;,
      &quot;authority&quot;: &quot;Kubernetes Project&quot;,
      &quot;priority&quot;: &quot;P1&quot;,
      &quot;depth&quot;: 3,
      &quot;max_pages&quot;: 100,
      &quot;delay&quot;: 1500,
      &quot;doc_type&quot;: null,
      &quot;jurisdiction&quot;: null,
      &quot;metadata&quot;: {}
    }
  ]
}</code></pre>

  <p>
    Each <code>source_name</code> maps to a directory in the crawl and chunk output. The loader
    uses this mapping to attach metadata (authority, jurisdiction, doc_type) to each document
    and fragment.
  </p>
  <p>
    See <a href="manifest-format.html">manifest-format.html</a> for the full schema reference.
  </p>
</section>

<!-- ────────── Examples ────────── -->
<section id="examples">
  <h2>Examples</h2>

  <h3>Generic: Kubernetes Networking</h3>
<pre><code>/build-kg kubernetes networking

# Claude generates ontology: Component, Concept, Configuration
# Discovers sources: kubernetes.io, cilium.io, calico docs
# Crawls ~200 pages, chunks, loads, parses
# Result: queryable KG with Component-USES-Concept relationships</code></pre>

  <h3>Generic: Machine Learning</h3>
<pre><code>/build-kg machine learning optimization algorithms

# Claude generates ontology: Algorithm, Technique, Application, Paper
# Discovers: arxiv papers, textbook sites, framework docs
# Result: KG connecting algorithms to techniques and applications</code></pre>

  <h3>Regulatory: Singapore F&amp;B</h3>
<pre><code>/build-kg full regulatory compliance landscape of Singapore for F&amp;B

# Uses food-safety domain profile (pre-built ontology)
# Discovers 12 sources across SFA, Parliament, HPB, MUIS
# Result: ~2,400 provisions, ~6,000 requirements, ~5,700 constraints</code></pre>

  <h3>Regulatory: GDPR Compliance</h3>
<pre><code>/build-kg GDPR compliance requirements for SaaS companies

# Uses data-privacy domain profile
# Discovers GDPR text, EDPB guidelines, ICO guidance
# Result: provisions with consent, data_transfer, breach_notification requirements</code></pre>

  <h3>Querying Your Graph</h3>
<pre><code>-- Count nodes by type
SELECT * FROM cypher('kg_k8s_net', $$
    MATCH (n:Component) RETURN count(n)
$$) as (cnt agtype);

-- Find relationships
SELECT * FROM cypher('kg_k8s_net', $$
    MATCH (c:Component)-[:USES]-&gt;(concept:Concept)
    RETURN c.name, concept.name, concept.category
    LIMIT 10
$$) as (component agtype, concept agtype, category agtype);

-- Traverse the graph (multi-hop)
SELECT * FROM cypher('kg_k8s_net', $$
    MATCH (a:Component)-[:DEPENDS_ON]-&gt;(b:Component)-[:USES]-&gt;(c:Concept)
    RETURN a.name, b.name, c.name
    LIMIT 10
$$) as (comp_a agtype, comp_b agtype, concept agtype);

-- Find all provisions for a jurisdiction (regulatory)
SELECT * FROM cypher('reg_sg_fb', $$
    MATCH (p:Provision)
    WHERE p.jurisdiction = 'SG'
    RETURN p.provision_id, p.authority, p.text
    LIMIT 20
$$) as (id agtype, authority agtype, text agtype);</code></pre>
</section>

<!-- ────────── Cost ────────── -->
<section id="cost">
  <h2>Cost</h2>
  <p>
    The only cost is LLM API calls during the parse phase. Everything else &mdash; crawling,
    chunking, loading, database &mdash; runs locally for free.
  </p>

  <table>
    <tr><th>Fragments</th><th>Sync Parser</th><th>Batch Parser (50% off)</th></tr>
    <tr><td>100</td><td>~$0.03</td><td>~$0.015</td></tr>
    <tr><td>1,000</td><td>~$0.30</td><td>~$0.15</td></tr>
    <tr><td>5,000</td><td>~$1.50</td><td>~$0.75</td></tr>
    <tr><td>10,000</td><td>~$3.00</td><td>~$1.50</td></tr>
  </table>

  <div class="callout tip">
    <span class="callout-title">Tip</span>
    Use <code>build-kg-parse --test</code> to verify with 5 fragments (cost: &lt; $0.01)
    before committing to a full run.
  </div>
</section>

<!-- ────────── Troubleshooting ────────── -->
<section id="troubleshooting">
  <h2>Troubleshooting</h2>
  <p>Quick reference for the most common errors. See <a href="troubleshooting.html">troubleshooting.html</a> for detailed solutions with full stack traces and step-by-step fixes.</p>

  <table>
    <tr><th>Error</th><th>Phase</th><th>Solution</th></tr>
    <tr>
      <td>Connection refused on port 5432</td>
      <td>Any</td>
      <td>Start the database: <code>docker compose -f db/docker-compose.yml up -d</code></td>
    </tr>
    <tr>
      <td>relation "source_fragment" does not exist</td>
      <td>Load / Parse</td>
      <td>Run <code>make db-reset</code> or execute <code>db/init.sql</code> manually</td>
    </tr>
    <tr>
      <td>AGE extension not found</td>
      <td>Setup</td>
      <td>Ensure you are using the Apache AGE Docker image, then run <code>build-kg-setup</code></td>
    </tr>
    <tr>
      <td>OpenAI API error 401</td>
      <td>Parse</td>
      <td>Check <code>OPENAI_API_KEY</code> in <code>.env</code>. Verify with <code>build-kg-verify</code></td>
    </tr>
    <tr>
      <td>Chromium not found</td>
      <td>Crawl</td>
      <td>Run <code>crawl4ai-setup</code> to install the browser</td>
    </tr>
    <tr>
      <td>No fragments found</td>
      <td>Parse</td>
      <td>Verify <code>build-kg-load</code> ran successfully. Check fragment count in DB</td>
    </tr>
    <tr>
      <td>Ontology file not found</td>
      <td>Parse / Setup</td>
      <td>Check <code>--ontology</code> path. Use <code>--domain</code> for built-in ontologies</td>
    </tr>
    <tr>
      <td>Batch still in "validating"</td>
      <td>Batch</td>
      <td>Wait; OpenAI batches can take 1&ndash;24 hours</td>
    </tr>
    <tr>
      <td>DB_PASSWORD is required</td>
      <td>Any</td>
      <td>Run <code>cp .env.example .env</code> and set credentials</td>
    </tr>
    <tr>
      <td>Empty entities in LLM output</td>
      <td>Parse</td>
      <td>Check ontology matches content. Try larger <code>--max-chars</code> for chunking</td>
    </tr>
    <tr>
      <td>PDF support not installed</td>
      <td>Chunk</td>
      <td>Install the PDF extra: <code>pip install &quot;build-kg[pdf]&quot;</code></td>
    </tr>
  </table>

  <h3>Most Common Fixes</h3>

  <h4>Database not running</h4>
  <p>
    If you see "Connection refused" or any database error, start the container first:
  </p>
<pre><code>docker compose -f db/docker-compose.yml up -d
docker compose -f db/docker-compose.yml ps    # verify it is healthy</code></pre>

  <h4>Missing tables after DB restart</h4>
  <p>
    If the Docker volume was reset, tables may be missing. Reinitialize:
  </p>
<pre><code>make db-reset
# or manually:
docker exec -i build-kg-db psql -U buildkg -d buildkg &lt; db/init.sql</code></pre>

  <h4>API key issues</h4>
  <p>Run the built-in verification command to check all connections:</p>
<pre><code>build-kg-verify</code></pre>

  <h4>Getting more help</h4>
  <p>
    If your issue is not listed here, open an issue at
    <a href="https://github.com/agtm1199/build-kg/issues" target="_blank" rel="noopener">github.com/agtm1199/build-kg/issues</a>
    with the exact error message, the command you ran, your Python version, and your OS.
  </p>
</section>

<!-- ────────── FAQ ────────── -->
<section id="faq">
  <h2>FAQ</h2>

  <div class="faq-item">
    <div class="faq-q">What topics can I use?</div>
    <div class="faq-a">
      Any topic. Generic topics (e.g., "kubernetes networking", "machine learning") auto-generate an ontology
      tailored to the subject. Regulatory domains (e.g., food safety, GDPR) use pre-built profiles
      with a Provision / Requirement / Constraint structure.
    </div>
  </div>

  <div class="faq-item">
    <div class="faq-q">How much does it cost?</div>
    <div class="faq-a">
      Only LLM API costs for the parse phase. Everything else is free and local.
      Approximately <strong>~$0.30 per 1,000 fragments</strong> with the sync parser, or
      <strong>~$0.15 per 1,000 fragments</strong> using the Batch API (50% cheaper).
    </div>
  </div>

  <div class="faq-item">
    <div class="faq-q">Can I use my own ontology?</div>
    <div class="faq-a">
      Yes. Create a YAML file defining your node types, edge types, and JSON schema, then
      pass it with the <code>--ontology</code> flag. You can also create a full domain profile
      with custom parsing instructions and discovery templates.
    </div>
  </div>

  <div class="faq-item">
    <div class="faq-q">Do I need Claude Code?</div>
    <div class="faq-a">
      No. The CLI tools (<code>build-kg-crawl</code>, <code>build-kg-chunk</code>,
      <code>build-kg-load</code>, <code>build-kg-parse</code>) work standalone. The Claude Code
      <code>/build-kg</code> skill simply automates all phases end-to-end.
    </div>
  </div>

  <div class="faq-item">
    <div class="faq-q">What LLM does it use?</div>
    <div class="faq-a">
      GPT-4o-mini by default. Configurable via the <code>OPENAI_MODEL</code> environment variable
      in your <code>.env</code> file.
    </div>
  </div>

  <div class="faq-item">
    <div class="faq-q">Can I export the graph?</div>
    <div class="faq-a">
      Yes. It is standard PostgreSQL with the Apache AGE extension. Use <code>pg_dump</code>,
      Cypher queries, or any PostgreSQL client to export data. You can also query the graph
      directly from any application that connects to PostgreSQL.
    </div>
  </div>
</section>

<!-- ────────── Footer ────────── -->
<footer class="footer">
  <p>build-kg &mdash; Apache 2.0 License &mdash; <a href="https://github.com/agtm1199/build-kg">GitHub</a></p>
</footer>

</div><!-- /.main -->

<!-- ═══════════ JavaScript ═══════════ -->
<script>
(function () {
  'use strict';

  // ── Sidebar toggle (mobile) ──
  var sidebar = document.getElementById('sidebar');
  var toggle = document.getElementById('sidebarToggle');
  var overlay = document.getElementById('sidebarOverlay');

  function openSidebar() {
    sidebar.classList.add('open');
    overlay.classList.add('visible');
  }

  function closeSidebar() {
    sidebar.classList.remove('open');
    overlay.classList.remove('visible');
  }

  toggle.addEventListener('click', function () {
    if (sidebar.classList.contains('open')) {
      closeSidebar();
    } else {
      openSidebar();
    }
  });

  overlay.addEventListener('click', closeSidebar);

  // Close sidebar when a link is clicked (mobile)
  var sidebarLinks = sidebar.querySelectorAll('a');
  sidebarLinks.forEach(function (link) {
    link.addEventListener('click', function () {
      if (window.innerWidth < 768) {
        closeSidebar();
      }
    });
  });

  // ── Intersection Observer: highlight active sidebar section ──
  var sections = document.querySelectorAll('section[id]');
  var navLinks = document.querySelectorAll('.sidebar-group li a');

  // Build a map from section id to sidebar link
  var linkMap = {};
  navLinks.forEach(function (link) {
    var href = link.getAttribute('href');
    if (href && href.startsWith('#')) {
      linkMap[href.substring(1)] = link;
    }
  });

  var observerOptions = {
    root: null,
    rootMargin: '-80px 0px -60% 0px',
    threshold: 0
  };

  var currentActive = null;

  var observer = new IntersectionObserver(function (entries) {
    entries.forEach(function (entry) {
      if (entry.isIntersecting) {
        var id = entry.target.getAttribute('id');
        if (linkMap[id]) {
          if (currentActive) {
            currentActive.classList.remove('active');
          }
          linkMap[id].classList.add('active');
          currentActive = linkMap[id];
        }
      }
    });
  }, observerOptions);

  sections.forEach(function (section) {
    observer.observe(section);
  });

  // ── Smooth scroll with offset for fixed nav ──
  document.querySelectorAll('a[href^="#"]').forEach(function (anchor) {
    anchor.addEventListener('click', function (e) {
      var targetId = this.getAttribute('href').substring(1);
      var target = document.getElementById(targetId);
      if (target) {
        e.preventDefault();
        var navHeight = 56;
        var offset = 24;
        var y = target.getBoundingClientRect().top + window.pageYOffset - navHeight - offset;
        window.scrollTo({ top: y, behavior: 'smooth' });

        // Update URL hash without jumping
        if (history.pushState) {
          history.pushState(null, null, '#' + targetId);
        }
      }
    });
  });

})();
</script>
</body>
</html>
