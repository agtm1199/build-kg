<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>build-kg Usage Guide</title>
<style>
  :root {
    --bg: #0d1117;
    --surface: #161b22;
    --border: #30363d;
    --text: #c9d1d9;
    --text-muted: #8b949e;
    --heading: #f0f6fc;
    --link: #58a6ff;
    --accent: #1f6feb;
    --green: #3fb950;
    --orange: #d29922;
    --red: #f85149;
    --purple: #bc8cff;
    --code-bg: #0d1117;
    --inline-code-bg: #1c2128;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  body {
    font-family: 'JetBrains Mono', 'Fira Code', 'SF Mono', 'Cascadia Code', 'Consolas', 'Liberation Mono', monospace;
    background: var(--bg);
    color: var(--text);
    line-height: 1.6;
    font-size: 16px;
  }

  .container {
    max-width: 960px;
    margin: 0 auto;
    padding: 2rem 1.5rem;
  }

  /* Header */
  .hero {
    text-align: center;
    padding: 3rem 0;
    border-bottom: 1px solid var(--border);
    margin-bottom: 2rem;
  }

  .hero h1 {
    font-size: 2.5rem;
    color: var(--heading);
    margin-bottom: 0.5rem;
    letter-spacing: -0.02em;
  }

  .hero .tagline {
    font-size: 1.2rem;
    color: var(--text-muted);
    margin-bottom: 1.5rem;
  }

  .hero .badges {
    display: flex;
    gap: 0.5rem;
    justify-content: center;
    flex-wrap: wrap;
  }

  .badge {
    display: inline-block;
    padding: 0.25rem 0.75rem;
    border-radius: 2rem;
    font-size: 0.8rem;
    font-weight: 600;
    border: 1px solid var(--border);
    color: var(--text-muted);
  }

  .badge.green { border-color: var(--green); color: var(--green); }
  .badge.blue { border-color: var(--link); color: var(--link); }
  .badge.purple { border-color: var(--purple); color: var(--purple); }

  /* Navigation */
  .toc {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 6px;
    padding: 1.5rem 2rem;
    margin-bottom: 3rem;
  }

  .toc h2 {
    font-size: 1.1rem;
    color: var(--heading);
    margin-bottom: 1rem;
    text-transform: uppercase;
    letter-spacing: 0.05em;
  }

  .toc ol {
    list-style: none;
    counter-reset: toc;
    columns: 2;
    column-gap: 2rem;
  }

  .toc li {
    counter-increment: toc;
    padding: 0.25rem 0;
  }

  .toc li::before {
    content: counter(toc) ".";
    color: var(--text-muted);
    margin-right: 0.5rem;
    font-size: 0.85rem;
  }

  .toc a {
    color: var(--link);
    text-decoration: none;
    font-size: 0.95rem;
  }

  .toc a:hover { text-decoration: underline; }

  /* Sections */
  section {
    margin-bottom: 3rem;
    padding-bottom: 2rem;
    border-bottom: 1px solid var(--border);
  }

  section:last-child { border-bottom: none; }

  h2 {
    font-size: 1.8rem;
    color: var(--heading);
    margin-bottom: 1rem;
    padding-top: 1rem;
  }

  h3 {
    font-size: 1.3rem;
    color: var(--heading);
    margin: 1.5rem 0 0.75rem;
  }

  h4 {
    font-size: 1.05rem;
    color: var(--heading);
    margin: 1.25rem 0 0.5rem;
  }

  p { margin-bottom: 1rem; }

  a { color: var(--link); text-decoration: none; }
  a:hover { text-decoration: underline; }

  /* Code blocks */
  pre {
    background: var(--code-bg);
    border: 1px solid var(--border);
    border-radius: 6px;
    padding: 1rem 1.25rem;
    overflow-x: auto;
    margin: 1rem 0;
    font-size: 0.875rem;
    line-height: 1.5;
  }

  code {
    font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
    font-size: 0.875em;
  }

  :not(pre) > code {
    background: var(--inline-code-bg);
    padding: 0.15em 0.4em;
    border-radius: 3px;
    font-size: 0.85em;
  }

  /* Tables */
  table {
    width: 100%;
    border-collapse: collapse;
    margin: 1rem 0;
    font-size: 0.9rem;
  }

  th, td {
    text-align: left;
    padding: 0.6rem 0.8rem;
    border: 1px solid var(--border);
  }

  th {
    background: var(--surface);
    color: var(--heading);
    font-weight: 600;
  }

  tr:nth-child(even) { background: rgba(22, 27, 34, 0.5); }

  /* Callouts */
  .callout {
    border-left: 3px solid var(--accent);
    background: var(--surface);
    padding: 1rem 1.25rem;
    border-radius: 0 6px 6px 0;
    margin: 1rem 0;
  }

  .callout.tip { border-left-color: var(--green); }
  .callout.warn { border-left-color: var(--orange); }
  .callout.danger { border-left-color: var(--red); }

  .callout strong {
    display: block;
    margin-bottom: 0.25rem;
    color: var(--heading);
  }

  /* Pipeline diagram */
  .pipeline {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(100px, 1fr));
    gap: 0.5rem;
    margin: 1.5rem 0;
  }

  .pipeline-step {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 6px;
    padding: 0.75rem;
    text-align: center;
    font-size: 0.8rem;
    position: relative;
  }

  .pipeline-step .phase {
    font-size: 0.7rem;
    color: var(--text-muted);
    text-transform: uppercase;
    letter-spacing: 0.05em;
  }

  .pipeline-step .name {
    font-weight: 600;
    color: var(--heading);
    margin: 0.25rem 0;
    font-size: 0.85rem;
  }

  .pipeline-step .tool {
    font-size: 0.7rem;
    color: var(--purple);
  }

  /* Comparison table */
  .compare-highlight { color: var(--green); font-weight: 600; }

  /* Command reference cards */
  .cmd-card {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 6px;
    padding: 1.25rem;
    margin: 0.75rem 0;
  }

  .cmd-card h4 {
    margin-top: 0;
    display: flex;
    align-items: center;
    gap: 0.5rem;
  }

  .cmd-card .cmd-name {
    font-family: 'SFMono-Regular', Consolas, monospace;
    color: var(--green);
    font-size: 1rem;
  }

  /* Responsive */
  @media (max-width: 700px) {
    .toc ol { columns: 1; }
    .hero h1 { font-size: 2rem; }
    .pipeline { grid-template-columns: repeat(4, 1fr); }
  }
</style>
</head>
<body>

<nav style="position:sticky;top:0;z-index:100;background:var(--surface);border-bottom:1px solid var(--border);padding:0.75rem 1.5rem;display:flex;align-items:center;gap:1.5rem;font-size:0.9rem;backdrop-filter:blur(8px);">
  <a href="../site/index.html" style="color:var(--heading);font-weight:700;text-decoration:none;">build-<span style="color:var(--link)">kg</span></a>
  <a href="index.html">Docs</a>
  <a href="guide.html" style="color:var(--heading);">Guide</a>
  <a href="../site/guide.html">Full Guide</a>
  <a href="https://github.com/mergen-ai/build-kg" style="margin-left:auto;">GitHub</a>
</nav>

<div class="container">

<!-- Hero -->
<header class="hero">
  <h1>build-kg</h1>
  <p class="tagline">One command. Any topic. Knowledge graph in your own PostgreSQL.</p>
  <div class="badges">
    <span class="badge green">Apache 2.0</span>
    <span class="badge blue">Python 3.10+</span>
    <span class="badge purple">Apache AGE</span>
  </div>
</header>

<!-- Table of Contents -->
<nav class="toc">
  <h2>Contents</h2>
  <ol>
    <li><a href="#overview">Overview</a></li>
    <li><a href="#installation">Installation</a></li>
    <li><a href="#quickstart">Quickstart</a></li>
    <li><a href="#pipeline">Pipeline</a></li>
    <li><a href="#ontology">Ontology System</a></li>
    <li><a href="#domain-profiles">Domain Profiles</a></li>
    <li><a href="#cli-reference">CLI Reference</a></li>
    <li><a href="#configuration">Configuration</a></li>
    <li><a href="#examples">Examples</a></li>
    <li><a href="#cost">Cost</a></li>
    <li><a href="#troubleshooting">Troubleshooting</a></li>
    <li><a href="#contributing">Contributing</a></li>
  </ol>
</nav>

<!-- 1. Overview -->
<section id="overview">
  <h2>1. Overview</h2>
  <p>build-kg turns any topic into a structured knowledge graph stored in Apache AGE (PostgreSQL). No vendor lock-in. No hosting fees. Just your own database.</p>

  <h3>How it works</h3>
  <p>Give build-kg a topic, and Claude autonomously:</p>
  <ol>
    <li>Generates an ontology (the graph structure) tailored to your topic</li>
    <li>Researches authoritative sources via 5-round discovery</li>
    <li>Crawls official documentation and websites</li>
    <li>Chunks documents into manageable fragments</li>
    <li>Loads fragments into PostgreSQL</li>
    <li>Parses each fragment with an LLM into graph nodes and edges</li>
  </ol>

  <h3>How it's different</h3>
  <table>
    <tr><th></th><th>build-kg</th><th>LangChain / LlamaIndex</th><th>Neo4j Aura</th></tr>
    <tr><td><strong>Graph hosting</strong></td><td class="compare-highlight">Your own PostgreSQL</td><td>Their infra</td><td>Neo4j cloud ($$$)</td></tr>
    <tr><td><strong>Vendor lock-in</strong></td><td class="compare-highlight">None &mdash; it's just AGE</td><td>Their SDK</td><td>Their platform</td></tr>
    <tr><td><strong>Ontology</strong></td><td class="compare-highlight">Auto-generated by Claude</td><td>You define it</td><td>You define it</td></tr>
    <tr><td><strong>Interface</strong></td><td><code>/build-kg</code> in Claude Code</td><td>Python code</td><td>Dashboard/API</td></tr>
    <tr><td><strong>Cost</strong></td><td>LLM API calls only</td><td>LLM + hosting</td><td>LLM + hosting + platform</td></tr>
  </table>
</section>

<!-- 2. Installation -->
<section id="installation">
  <h2>2. Installation</h2>

  <h3>Prerequisites</h3>
  <ul>
    <li><strong>Python 3.10+</strong></li>
    <li><strong>Docker</strong> (for PostgreSQL + Apache AGE)</li>
    <li><strong>OpenAI API key</strong> (for text parsing)</li>
  </ul>

  <h3>From source (recommended)</h3>
  <pre><code>git clone https://github.com/mergen-ai/build-kg.git
cd build-kg

# Full setup: creates venv, starts DB, initializes graph
make setup

# Or step-by-step:
python3 -m venv venv
source venv/bin/activate
pip install -e ".[dev]"
crawl4ai-setup
docker compose -f db/docker-compose.yml up -d
python -m build_kg.setup_graph</code></pre>

  <h3>From PyPI</h3>
  <pre><code>pip install build-kg</code></pre>

  <h3>Configure</h3>
  <pre><code>cp .env.example .env
# Edit .env and set OPENAI_API_KEY=sk-...

# Verify everything works
make verify</code></pre>
</section>

<!-- 3. Quickstart -->
<section id="quickstart">
  <h2>3. Quickstart</h2>

  <h3>With Claude Code (recommended)</h3>
  <p>If you use <a href="https://docs.anthropic.com/en/docs/claude-code">Claude Code</a>, the <code>/build-kg</code> skill automates the entire pipeline:</p>
  <pre><code>/build-kg kubernetes networking
/build-kg machine learning optimization algorithms
/build-kg GDPR compliance requirements for SaaS companies
/build-kg full regulatory compliance landscape of Singapore for F&amp;B</code></pre>
  <p>This runs all phases autonomously &mdash; generating the ontology, researching sources, crawling, chunking, loading, parsing, and reporting.</p>

  <h3>With CLI tools (manual)</h3>
  <pre><code># 1. Crawl a website
build-kg-crawl --url "https://kubernetes.io/docs/concepts/services-networking/" \
  --depth 2 --pages 50 --output ./output/

# 2. Chunk the crawled content
build-kg-chunk ./output/ ./chunks/ --strategy by_title --max-chars 1000

# 3. Load chunks to database
build-kg-load ./chunks/ --manifest ./crawl_manifest.json

# 4. Set up graph with your ontology
AGE_GRAPH_NAME=kg_k8s_net python -m build_kg.setup_graph --ontology ./ontology.yaml

# 5. Parse fragments into the knowledge graph
AGE_GRAPH_NAME=kg_k8s_net build-kg-parse --ontology ./ontology.yaml

# 6. Or use the batch API (50% cheaper)
build-kg-parse-batch prepare --ontology ./ontology.yaml
build-kg-parse-batch submit batch_data/batch_requests.jsonl
build-kg-parse-batch status &lt;batch_id&gt; --watch
build-kg-parse-batch process &lt;batch_id&gt; --ontology ./ontology.yaml</code></pre>
</section>

<!-- 4. Pipeline -->
<section id="pipeline">
  <h2>4. Pipeline</h2>

  <div class="pipeline">
    <div class="pipeline-step">
      <div class="phase">Phase 0</div>
      <div class="name">Init</div>
      <div class="tool">graph name, dirs</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 0.5</div>
      <div class="name">Ontology</div>
      <div class="tool">auto-gen or profile</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 1</div>
      <div class="name">Discover</div>
      <div class="tool">WebSearch</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 2</div>
      <div class="name">Crawl</div>
      <div class="tool">Crawl4AI</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 3</div>
      <div class="name">Chunk</div>
      <div class="tool">Unstructured</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 4</div>
      <div class="name">Load</div>
      <div class="tool">PostgreSQL</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 5</div>
      <div class="name">Parse</div>
      <div class="tool">GPT-4o-mini</div>
    </div>
    <div class="pipeline-step">
      <div class="phase">Phase 6</div>
      <div class="name">Validate</div>
      <div class="tool">Cypher queries</div>
    </div>
  </div>

  <h3>Phase 0: Initialize</h3>
  <p>Create a working directory and choose a graph name. Convention: <code>reg_&lt;country&gt;_&lt;domain&gt;</code> for regulatory topics, <code>kg_&lt;topic&gt;</code> for generic topics.</p>

  <h3>Phase 0.5: Ontology Generation</h3>
  <p>The key differentiator of build-kg. For generic topics, Claude analyzes your topic and auto-generates an ontology &mdash; the node types, edge types, properties, and JSON schema. For regulatory domain profiles, the ontology is pre-defined in the profile YAML.</p>

  <h3>Phase 1: Source Discovery</h3>
  <p>A 5-round methodology identifies authoritative sources for the topic. Outputs a crawl manifest listing every URL to crawl with metadata and priority tiers.</p>

  <h3>Phase 2: Crawl</h3>
  <p>Breadth-first web crawling using Crawl4AI with headless Chromium. Supports JavaScript-rendered pages. Configurable depth, page limits, and delay.</p>

  <h3>Phase 3: Chunk</h3>
  <p>Documents are split into semantically coherent fragments using the Unstructured library. Two strategies: <code>by_title</code> (respects headings) and <code>basic</code> (uniform size).</p>

  <h3>Phase 4: Load</h3>
  <p>Chunks are loaded into PostgreSQL's <code>source_fragment</code> table with metadata from the crawl manifest. Adjacent chunks are linked via context fields.</p>

  <h3>Phase 5: Parse</h3>
  <p>Each fragment is sent to GPT-4o-mini with a structured prompt derived from the ontology. The LLM's JSON response is loaded into Apache AGE as graph nodes and edges.</p>

  <h3>Phase 6: Validate</h3>
  <p>Cypher queries count nodes by label from the ontology and produce a report card of the completed graph.</p>
</section>

<!-- 5. Ontology System -->
<section id="ontology">
  <h2>5. Ontology System</h2>
  <p>The ontology defines <em>what</em> your knowledge graph looks like &mdash; the types of nodes, their properties, and how they connect.</p>

  <h3>Auto-Generated Ontology</h3>
  <p>For generic topics (using the <code>default</code> profile or no profile), Claude automatically generates an ontology. Example for <strong>"kubernetes networking"</strong>:</p>
  <pre><code>nodes:
  - label: Component
    description: "A Kubernetes networking component"
    properties:
      name: string
      type: string
      description: string
      layer: string
  - label: Concept
    description: "A networking concept or protocol"
    properties:
      name: string
      description: string
      category: string
  - label: Configuration
    description: "A configuration option or setting"
    properties:
      name: string
      description: string
      default_value: string
edges:
  - label: USES
    source: Component
    target: Concept
    description: "Component uses this concept"
  - label: CONFIGURES
    source: Configuration
    target: Component
    description: "Configuration applies to component"
  - label: DEPENDS_ON
    source: Component
    target: Component
    description: "Component depends on another"
root_node: Component
json_schema: |
  {
    "entities": [
      {"_label": "Component|Concept|Configuration", "name": "...", ...}
    ],
    "relationships": [
      {"_label": "USES|CONFIGURES|DEPENDS_ON", "_from_index": 0, "_to_index": 1}
    ]
  }</code></pre>

  <h3>Pre-Built Ontology (Domain Profiles)</h3>
  <p>Regulatory domain profiles include a pre-built ontology with <code>Provision &rarr; Requirement &rarr; Constraint</code> nodes. This ontology is optimized for regulatory compliance analysis with machine-testable constraints.</p>

  <h3>OntologyConfig Data Model</h3>
  <table>
    <tr><th>Model</th><th>Fields</th><th>Description</th></tr>
    <tr><td><code>NodeDef</code></td><td><code>label</code>, <code>description</code>, <code>properties</code></td><td>A node type in the graph</td></tr>
    <tr><td><code>EdgeDef</code></td><td><code>label</code>, <code>source</code>, <code>target</code>, <code>description</code></td><td>An edge type connecting two node types</td></tr>
    <tr><td><code>OntologyConfig</code></td><td><code>nodes</code>, <code>edges</code>, <code>root_node</code>, <code>json_schema</code></td><td>Complete ontology definition</td></tr>
  </table>

  <div class="callout tip">
    <strong>Tip</strong>
    The ontology is the most important part of your knowledge graph. When auto-generated, review it carefully before proceeding. You can edit the <code>ontology.yaml</code> file to adjust node types and properties.
  </div>
</section>

<!-- 6. Domain Profiles -->
<section id="domain-profiles">
  <h2>6. Domain Profiles</h2>
  <p>Domain profiles are YAML files that parameterize the entire pipeline: ontology, LLM prompt, ID extraction patterns, and source discovery templates.</p>

  <h3>Built-in Profiles</h3>
  <table>
    <tr><th>Profile</th><th>Ontology</th><th>Domain</th></tr>
    <tr><td><code>default</code></td><td>None (auto-generated)</td><td>Any topic</td></tr>
    <tr><td><code>food-safety</code></td><td>Provision/Requirement/Constraint</td><td>CFIA, FDA, SFA food safety</td></tr>
    <tr><td><code>financial-aml</code></td><td>Provision/Requirement/Constraint</td><td>AML/KYC financial compliance</td></tr>
    <tr><td><code>data-privacy</code></td><td>Provision/Requirement/Constraint</td><td>GDPR, CCPA, data protection</td></tr>
  </table>

  <h3>Selecting a Profile</h3>
  <pre><code># Via CLI flag
build-kg-parse --domain financial-aml

# Via environment variable
DOMAIN=financial-aml build-kg-parse

# Custom profile file
build-kg-parse --domain /path/to/my-domain.yaml

# List all available profiles
build-kg-domains</code></pre>

  <h3>Profile Inheritance</h3>
  <p>Profiles can inherit from a base using <code>extends: default</code>. Child fields override parent fields via deep merge.</p>

  <h3>Profile Structure</h3>
  <pre><code>name: "My Domain"
description: "Custom domain profile"
version: "1.0"
extends: default

ontology:
  root_node: MyEntity
  nodes:
    - label: MyEntity
      description: "Primary entity type"
      properties: {name: string, type: string}
  edges:
    - label: RELATES_TO
      source: MyEntity
      target: MyEntity
  json_schema: |
    {"entities": [...], "relationships": [...]}

parsing:
  system_message: "You are an expert in..."
  requirement_types: [...]

id_patterns:
  patterns: {}

discovery:
  search_templates:
    - "&lt;topic&gt; official documentation"
  sub_domains:
    - name: "Sub-area 1"
      description: "..."</code></pre>
</section>

<!-- 7. CLI Reference -->
<section id="cli-reference">
  <h2>7. CLI Reference</h2>

  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-crawl</span></h4>
    <p>Crawl websites to markdown/HTML/JSON using headless Chromium.</p>
    <table>
      <tr><th>Flag</th><th>Default</th><th>Description</th></tr>
      <tr><td><code>--url URL</code></td><td>(required)</td><td>Starting URL to crawl</td></tr>
      <tr><td><code>--depth N</code></td><td>2</td><td>Maximum crawl depth</td></tr>
      <tr><td><code>--pages N</code></td><td>10</td><td>Maximum pages to visit</td></tr>
      <tr><td><code>--delay MS</code></td><td>1000</td><td>Delay between visits (ms)</td></tr>
      <tr><td><code>--format FMT</code></td><td>markdown</td><td>Output: markdown, html, json</td></tr>
      <tr><td><code>--output DIR</code></td><td>./output</td><td>Output directory</td></tr>
    </table>
  </div>

  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-chunk</span></h4>
    <p>Chunk documents into JSON fragments using Unstructured.</p>
    <table>
      <tr><th>Flag</th><th>Default</th><th>Description</th></tr>
      <tr><td><code>&lt;input_dir&gt;</code></td><td>(required)</td><td>Input directory with .md/.pdf files</td></tr>
      <tr><td><code>&lt;output_dir&gt;</code></td><td>(required)</td><td>Output directory for JSON chunks</td></tr>
      <tr><td><code>--strategy</code></td><td>by_title</td><td>Chunking strategy: by_title or basic</td></tr>
      <tr><td><code>--max-chars N</code></td><td>1000</td><td>Maximum characters per chunk</td></tr>
      <tr><td><code>--overlap N</code></td><td>0</td><td>Character overlap between chunks</td></tr>
    </table>
  </div>

  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-load</span></h4>
    <p>Load chunks into PostgreSQL with manifest metadata.</p>
    <table>
      <tr><th>Flag</th><th>Default</th><th>Description</th></tr>
      <tr><td><code>&lt;chunk_dir&gt;</code></td><td>(required)</td><td>Directory with JSON chunk files</td></tr>
      <tr><td><code>--manifest PATH</code></td><td>(required)</td><td>Path to crawl_manifest.json</td></tr>
      <tr><td><code>--dry-run</code></td><td>off</td><td>Preview without inserting</td></tr>
    </table>
  </div>

  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-parse</span></h4>
    <p>Parse fragments into graph nodes using OpenAI (sync).</p>
    <table>
      <tr><th>Flag</th><th>Default</th><th>Description</th></tr>
      <tr><td><code>--limit N</code></td><td>all</td><td>Max fragments to process</td></tr>
      <tr><td><code>--offset N</code></td><td>0</td><td>Skip first N fragments</td></tr>
      <tr><td><code>--jurisdiction CODE</code></td><td>all</td><td>Filter by jurisdiction</td></tr>
      <tr><td><code>--domain NAME</code></td><td>food-safety</td><td>Domain profile name or path</td></tr>
      <tr><td><code>--ontology PATH</code></td><td>none</td><td>Ontology YAML file</td></tr>
      <tr><td><code>--test</code></td><td>off</td><td>Process only 5 fragments</td></tr>
    </table>
  </div>

  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-parse-batch</span></h4>
    <p>Parse fragments using OpenAI Batch API (50% cheaper).</p>
    <p>Subcommands: <code>prepare</code>, <code>submit</code>, <code>status</code>, <code>process</code></p>
    <pre><code>build-kg-parse-batch prepare [--ontology PATH] [--jurisdiction CODE]
build-kg-parse-batch submit &lt;batch_file&gt;
build-kg-parse-batch status &lt;batch_id&gt; [--watch]
build-kg-parse-batch process &lt;batch_id&gt; [--ontology PATH]</code></pre>
  </div>

  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-setup</span></h4>
    <p>Create Apache AGE extension and graph schema.</p>
    <table>
      <tr><th>Flag</th><th>Default</th><th>Description</th></tr>
      <tr><td><code>--ontology PATH</code></td><td>none</td><td>Create vertex labels from ontology</td></tr>
    </table>
  </div>

  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-verify</span></h4>
    <p>Verify database, AGE extension, and API key setup.</p>
  </div>

  <div class="cmd-card">
    <h4><span class="cmd-name">build-kg-domains</span></h4>
    <p>List all available domain profiles.</p>
  </div>
</section>

<!-- 8. Configuration -->
<section id="configuration">
  <h2>8. Configuration</h2>
  <p>All configuration is via <code>.env</code> file or environment variables:</p>

  <table>
    <tr><th>Variable</th><th>Default</th><th>Description</th></tr>
    <tr><td><code>DB_HOST</code></td><td>localhost</td><td>PostgreSQL host</td></tr>
    <tr><td><code>DB_PORT</code></td><td>5432</td><td>PostgreSQL port</td></tr>
    <tr><td><code>DB_NAME</code></td><td>buildkg</td><td>Database name</td></tr>
    <tr><td><code>DB_USER</code></td><td>buildkg</td><td>Database user</td></tr>
    <tr><td><code>DB_PASSWORD</code></td><td>&mdash;</td><td>Database password <strong>(required)</strong></td></tr>
    <tr><td><code>OPENAI_API_KEY</code></td><td>&mdash;</td><td>OpenAI API key <strong>(required)</strong></td></tr>
    <tr><td><code>OPENAI_MODEL</code></td><td>gpt-4o-mini</td><td>Model for parsing</td></tr>
    <tr><td><code>AGE_GRAPH_NAME</code></td><td>reg_ca</td><td>Apache AGE graph name</td></tr>
    <tr><td><code>BATCH_SIZE</code></td><td>10</td><td>Fragments per batch</td></tr>
    <tr><td><code>MAX_WORKERS</code></td><td>3</td><td>Concurrent workers</td></tr>
    <tr><td><code>DOMAIN</code></td><td>food-safety</td><td>Domain profile name or path</td></tr>
    <tr><td><code>RATE_LIMIT_DELAY</code></td><td>1.0</td><td>Seconds between API calls</td></tr>
  </table>
</section>

<!-- 9. Examples -->
<section id="examples">
  <h2>9. Examples</h2>

  <h3>Generic: Kubernetes Networking</h3>
  <pre><code>/build-kg kubernetes networking

# Claude generates ontology: Component, Concept, Configuration
# Discovers sources: kubernetes.io, cilium.io, calico docs
# Crawls ~200 pages, chunks, loads, parses
# Result: queryable KG with Component-USES-Concept relationships</code></pre>

  <h3>Generic: Machine Learning</h3>
  <pre><code>/build-kg machine learning optimization algorithms

# Claude generates ontology: Algorithm, Technique, Application, Paper
# Discovers: arxiv papers, textbook sites, framework docs
# Result: KG connecting algorithms to techniques and applications</code></pre>

  <h3>Regulatory: Singapore Food Safety</h3>
  <pre><code>/build-kg full regulatory compliance landscape of Singapore for F&amp;B

# Uses food-safety domain profile (pre-built ontology)
# Discovers 12 sources across SFA, Parliament, HPB, MUIS
# Result: ~2,400 provisions, ~6,000 requirements, ~5,700 constraints</code></pre>

  <h3>Regulatory: GDPR Compliance</h3>
  <pre><code>/build-kg GDPR compliance requirements for SaaS companies

# Uses data-privacy domain profile
# Discovers GDPR text, EDPB guidelines, ICO guidance
# Result: provisions with consent, data_transfer, breach_notification requirements</code></pre>

  <h3>Querying Your Graph</h3>
  <pre><code># Count nodes by type
SELECT * FROM cypher('kg_k8s_net', $$
    MATCH (n:Component) RETURN count(n)
$$) as (cnt agtype);

# Find relationships
SELECT * FROM cypher('kg_k8s_net', $$
    MATCH (c:Component)-[:USES]->(concept:Concept)
    RETURN c.name, concept.name, concept.category
    LIMIT 10
$$) as (component agtype, concept agtype, category agtype);

# Traverse the graph
SELECT * FROM cypher('kg_k8s_net', $$
    MATCH (a:Component)-[:DEPENDS_ON]->(b:Component)-[:USES]->(c:Concept)
    RETURN a.name, b.name, c.name
    LIMIT 10
$$) as (comp_a agtype, comp_b agtype, concept agtype);</code></pre>
</section>

<!-- 10. Cost -->
<section id="cost">
  <h2>10. Cost</h2>
  <p>The only cost is LLM API calls during parsing. Everything else runs locally for free.</p>

  <table>
    <tr><th>Fragments</th><th>Sync Parser</th><th>Batch Parser (50% off)</th></tr>
    <tr><td>100</td><td>~$0.03</td><td>~$0.015</td></tr>
    <tr><td>1,000</td><td>~$0.30</td><td>~$0.15</td></tr>
    <tr><td>5,000</td><td>~$1.50</td><td>~$0.75</td></tr>
    <tr><td>10,000</td><td>~$3.00</td><td>~$1.50</td></tr>
  </table>

  <div class="callout tip">
    <strong>Tip</strong>
    Use <code>build-kg-parse --test</code> to verify with 5 fragments (cost: &lt; $0.01) before running a full batch.
  </div>
</section>

<!-- 11. Troubleshooting -->
<section id="troubleshooting">
  <h2>11. Troubleshooting</h2>

  <table>
    <tr><th>Error</th><th>Phase</th><th>Solution</th></tr>
    <tr><td>Connection refused on port 5432</td><td>Any</td><td>Run <code>docker compose -f db/docker-compose.yml up -d</code></td></tr>
    <tr><td>relation "source_fragment" does not exist</td><td>Load/Parse</td><td>Run <code>make db-reset</code> or <code>docker exec -i build-kg-db psql -U buildkg -d buildkg &lt; db/init.sql</code></td></tr>
    <tr><td>AGE extension not found</td><td>Setup</td><td>Run <code>build-kg-setup</code> with the Apache AGE Docker image</td></tr>
    <tr><td>OpenAI API error 401</td><td>Parse</td><td>Check <code>OPENAI_API_KEY</code> in <code>.env</code></td></tr>
    <tr><td>Chromium not found</td><td>Crawl</td><td>Run <code>crawl4ai-setup</code></td></tr>
    <tr><td>No fragments found</td><td>Parse</td><td>Verify <code>build-kg-load</code> ran successfully</td></tr>
    <tr><td>invalid input value for enum</td><td>Load</td><td>Add jurisdiction: <code>ALTER TYPE market_code ADD VALUE 'XX';</code> or omit for generic topics</td></tr>
    <tr><td>Ontology file not found</td><td>Parse/Setup</td><td>Check <code>--ontology</code> path is correct</td></tr>
    <tr><td>Batch still in "validating"</td><td>Batch</td><td>Wait; OpenAI batches take 1-24 hours</td></tr>
    <tr><td>DB_PASSWORD is required</td><td>Any</td><td>Run <code>cp .env.example .env</code></td></tr>
  </table>

  <p>Full troubleshooting guide: <a href="troubleshooting.md">docs/troubleshooting.md</a></p>
</section>

<!-- 12. Contributing -->
<section id="contributing">
  <h2>12. Contributing</h2>

  <table>
    <tr><th>Contribution</th><th>Difficulty</th><th>Impact</th></tr>
    <tr><td>Add a domain profile</td><td>Low</td><td>High &mdash; unlocks a new domain</td></tr>
    <tr><td>Add ID extraction patterns</td><td>Low</td><td>Medium</td></tr>
    <tr><td>Improve documentation</td><td>Low</td><td>Medium</td></tr>
    <tr><td>Improve ontology generation</td><td>Medium</td><td>High</td></tr>
    <tr><td>Fix bugs / improve pipeline</td><td>Varies</td><td>High</td></tr>
  </table>

  <pre><code># Development setup
git clone https://github.com/YOUR_USERNAME/build-kg.git
cd build-kg
python3 -m venv venv &amp;&amp; source venv/bin/activate
pip install -e ".[dev]"
pytest tests/ -v</code></pre>

  <p>Full contributing guide: <a href="../CONTRIBUTING.md">CONTRIBUTING.md</a></p>
</section>

<footer style="text-align: center; padding: 2rem 0; color: var(--text-muted); font-size: 0.85rem;">
  <p>build-kg &mdash; Apache 2.0 License &mdash; <a href="https://github.com/mergen-ai/build-kg">GitHub</a></p>
</footer>

</div>
</body>
</html>
